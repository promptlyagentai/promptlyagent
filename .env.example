APP_NAME=Laravel
APP_ENV=local
APP_KEY=
APP_DEBUG=true
APP_URL=http://localhost

# Docker Sail User Mapping
# Set these to your host user's UID and GID to avoid permission issues
# Run: id -u (for WWWUSER) and id -g (for WWWGROUP)
WWWUSER=1000
WWWGROUP=1000

# Internal URL for container-to-container communication (Sail/Docker)
# Use service name from docker-compose.yml for queue workers to reach web server
APP_INTERNAL_URL=http://laravel.test

APP_LOCALE=en
APP_FALLBACK_LOCALE=en
APP_FAKER_LOCALE=en_US

APP_MAINTENANCE_DRIVER=file
# APP_MAINTENANCE_STORE=database

PHP_CLI_SERVER_WORKERS=4

BCRYPT_ROUNDS=12

# Feature Flags
ENABLE_CUSTOM_COLOR_SCHEMES=false
PROMPTLY_ENCOURAGE_DIRECT_ANSWERS=false

LOG_CHANNEL=stack
LOG_STACK=single
LOG_DEPRECATIONS_CHANNEL=null
LOG_LEVEL=debug

DB_CONNECTION=mysql
DB_HOST=mysql
DB_PORT=3306
DB_DATABASE=promptlyagent
DB_USERNAME=sail
DB_PASSWORD=password

SESSION_DRIVER=database
SESSION_LIFETIME=120
SESSION_ENCRYPT=false
SESSION_PATH=/
SESSION_DOMAIN=null

BROADCAST_CONNECTION=reverb
FILESYSTEM_DISK=local
LIVEWIRE_TEMPORARY_UPLOAD_DISK=local
QUEUE_CONNECTION=redis

# Storage Configuration
# Local development: Use FILESYSTEM_DISK=local and LIVEWIRE_TEMPORARY_UPLOAD_DISK=local
# Production: Configure AWS S3 credentials below and set FILESYSTEM_DISK=s3

CACHE_STORE=redis
# CACHE_PREFIX=

# Redis Configuration
# Single Redis instance (development, docker-compose)
# For Docker Sail: use service name "redis" from docker-compose.yml
REDIS_CLIENT=phpredis
REDIS_HOST=redis
REDIS_PASSWORD=null
REDIS_PORT=6379
REDIS_USERNAME=
REDIS_CACHE_DB=1
REDIS_QUEUE_DB=2
REDIS_EVENTSTREAM_DB=3
REDIS_QUEUE=default

# Reverb WebSocket Server Configuration
# REVERB_HOST is for browser connections (uses forwarded port)
# For internal container-to-container comms, use "reverb" service name
REVERB_APP_ID=promptlyagent
REVERB_APP_KEY=reverb-key
REVERB_APP_SECRET=reverb-secret
REVERB_HOST=localhost
REVERB_PORT=8080
REVERB_SCHEME=http

# For horizontal scaling in production, enable Redis pub/sub scaling
# REVERB_SCALING_ENABLED=false
# REVERB_SCALING_CHANNEL=reverb
# REVERB_SERVER_HOST=0.0.0.0
# REVERB_SERVER_PORT=8080

MAIL_MAILER=log
MAIL_SCHEME=null
MAIL_HOST=mailpit
MAIL_PORT=1025
MAIL_USERNAME=null
MAIL_PASSWORD=null
MAIL_FROM_ADDRESS="hello@example.com"
MAIL_FROM_NAME="${APP_NAME}"

AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_DEFAULT_REGION=us-east-1
AWS_REGION=us-east-1
AWS_BUCKET=
AWS_USE_PATH_STYLE_ENDPOINT=false
AWS_SESSION_TOKEN=
AWS_USE_DEFAULT_CREDENTIAL_PROVIDER=false

# S3-Compatible Storage Configuration (Kubernetes)
# For Kubernetes deployments, you can use:
# - AWS S3 with IRSA (IAM Roles for Service Accounts) - no static credentials needed
# - MinIO for local development: AWS_ENDPOINT=http://minio:9000, AWS_USE_PATH_STYLE_ENDPOINT=true
# - DigitalOcean Spaces: AWS_ENDPOINT=https://nyc3.digitaloceanspaces.com
# - Any S3-compatible storage provider
# AWS_ENDPOINT=

VITE_APP_NAME="${APP_NAME}"

# Searxng Search Engine
FORWARD_SEARXNG_PORT=4000
SEARXNG_URL=http://searxng:8080

# AI Model Configuration
# Define standardized AI models for different complexity tiers
# Low cost models for simple tasks (summaries, titles, basic analysis)
AI_LOW_COST_PROVIDER=openai
AI_LOW_COST_MODEL=gpt-4o-mini
AI_LOW_COST_MAX_TOKENS=512

# Medium complexity models for standard reasoning tasks
AI_MEDIUM_PROVIDER=openai
AI_MEDIUM_MODEL=gpt-4o
AI_MEDIUM_MAX_TOKENS=1024

# Complex reasoning models for advanced analysis and problem-solving
AI_COMPLEX_PROVIDER=openai
AI_COMPLEX_MODEL=gpt-4
AI_COMPLEX_MAX_TOKENS=2048

# AWS Bedrock Configuration (optional - for using Claude, Nova, Titan models via Bedrock)
# Uncomment and configure to use AWS Bedrock models:
# AI_COMPLEX_PROVIDER=bedrock
# AI_COMPLEX_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0
# AWS credentials configured above will be used

# Bedrock Embedding Models (optional - for using Titan embeddings)
# KNOWLEDGE_EMBEDDING_PROVIDER=bedrock
# KNOWLEDGE_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0

# =============================================================================
# AI Provider API Keys
# =============================================================================
# Configure API keys for AI providers. This app uses Prism PHP for multi-provider support.
# For additional providers (Anthropic, Gemini, Groq, Mistral, etc.), see:
# https://prismphp.com/getting-started/introduction.html

# OpenAI (GPT-4, GPT-4o, o1, o3, etc.)
OPENAI_API_KEY=

# AWS Bedrock (Claude, Nova, Titan models via AWS)
# Uses AWS credentials configured above (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION)

# Ollama (Local models - requires Ollama server running)
# OLLAMA_URL=http://localhost:11434

# Judge0 Code Execution Service
# Three deployment options:
# 1. Self-hosted Judge0: http://your-judge0-server:2358
# 2. RapidAPI (hosted): https://judge0-ce.p.rapidapi.com (requires API key)
# 3. Public instance: https://ce.judge0.com (testing only, not for production)
JUDGE0_URL=https://ce.judge0.com
JUDGE0_API_KEY=

# Judge0 client configuration
JUDGE0_TIMEOUT=30
JUDGE0_MAX_POLLING_ATTEMPTS=10
JUDGE0_POLLING_INTERVAL=1

# Code Execution Driver and Limits
CODE_EXECUTION_DRIVER=judge0
CODE_EXECUTION_CPU_TIME_LIMIT=5
CODE_EXECUTION_MEMORY_LIMIT=256000
CODE_EXECUTION_WALL_TIME_LIMIT=10
CODE_EXECUTION_MAX_OUTPUT_SIZE=10240

# Slack Integration (optional)
# Create a Slack app at https://api.slack.com/apps
# Required scopes: app_mentions:read, channels:history, channels:read, chat:write, chat:write.public,
#                  files:read, files:write, groups:history, im:history, im:write, users:read
SLACK_CLIENT_ID=
SLACK_CLIENT_SECRET=
SLACK_SIGNING_SECRET=

# Help Widget Configuration
# The AI agent ID to use for the interactive help widget
# If not set, will default to the first agent with name "Promptly Manual"
# HELP_WIDGET_AGENT_ID=

# GitHub Bug Reporting (optional)
# Enable bug reporting via the interactive help widget
# Creates GitHub issues using a bot account (global token)
# Optional per-user @mentions for attribution (set in user preferences)
GITHUB_BUG_REPORT_ENABLED=false
GITHUB_BUG_REPORT_TOKEN=
GITHUB_BUG_REPORT_REPO=
GITHUB_BUG_REPORT_ASSIGNEES=

# Chat Session Management
# Auto-archive old sessions after specified days (0 to disable)
# Sessions marked as "kept" are never auto-archived
CHAT_AUTO_ARCHIVE_ENABLED=true
CHAT_AUTO_ARCHIVE_DAYS=90
CHAT_SEARCH_ENABLED=true
CHAT_COUNTS_CACHE_MINUTES=5

# Google OAuth Auto-Admin Emails
# Comma-separated list of emails that should automatically become admins on first Google login
# Leave empty in production for security (manually assign admin via make:admin instead)
GOOGLE_AUTO_ADMIN_EMAILS=

